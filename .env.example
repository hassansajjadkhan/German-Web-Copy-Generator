# LLM Provider Configuration
# Supported providers: groq, openai
LLM_PROVIDER=groq

# Your Groq API Key (get it from https://console.groq.com)
LLM_API_KEY=gsk_your_api_key_here

# API Base URL (OpenAI-compatible endpoint)
# For Groq: https://api.groq.com/openai/v1
# For OpenAI: https://api.openai.com/v1
LLM_BASE_URL=https://api.groq.com/openai/v1

# Model to use
# For Groq: llama-3.3-70b-versatile, llama-3.1-70b-versatile, mixtral-8x7b-32768
# For OpenAI: gpt-4o-mini, gpt-4o
LLM_MODEL=llama-3.3-70b-versatile

# Optional: Rate limiting (requests per IP per hour)
RATE_LIMIT_PER_HOUR=10
